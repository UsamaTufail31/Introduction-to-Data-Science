{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 11/Dec/2023\n",
        "# CSC461 – Assignment4 – NLP\n",
        "# Usama Tufail\n",
        "# FA21-BSE-053\n",
        "# Compute BoW, TF, IDF, and then TF.IDF values for each term Sentences and also Compute the similarity between S1, S2, and S3 using cosine, manhattan, and euclidean distances."
      ],
      "metadata": {
        "id": "Q69aNA8rBT2e"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "aqH3opmW_q8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import important libraries\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cityblock\n",
        "import pandas as pd\n",
        "import math\n"
      ],
      "metadata": {
        "id": "GpF9WRk3_zfP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "documents = (\n",
        "    \"data science is one of the most important courses in computer science\",\n",
        "    \"this is one of the best data science courses\",\n",
        "    \"the data scientists perform data analysis\"\n",
        ")"
      ],
      "metadata": {
        "id": "2wF-WysV_1am"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find bag of words\n",
        "count_vectorizer = CountVectorizer()\n",
        "matrix= count_vectorizer.fit_transform(documents)\n",
        "tokens = count_vectorizer.get_feature_names_out()\n",
        "bow_matrix = matrix.toarray()\n",
        "df_bow = pd.DataFrame(data = bow_matrix, columns = tokens)\n",
        "print(\"Bag of Words Matrix:\")\n",
        "print(df_bow)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7ehehMT_9Pp",
        "outputId": "313bb409-21c3-4209-fb54-eeb083faad46"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words Matrix:\n",
            "   analysis  best  computer  courses  data  important  in  is  most  of  one  \\\n",
            "0         0     0         1        1     1          1   1   1     1   1    1   \n",
            "1         0     1         0        1     1          0   0   1     0   1    1   \n",
            "2         1     0         0        0     2          0   0   0     0   0    0   \n",
            "\n",
            "   perform  science  scientists  the  this  \n",
            "0        0        2           0    1     0  \n",
            "1        0        1           0    1     1  \n",
            "2        1        0           1    1     0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find term frequency\n",
        "def calculate_tf(corpus):\n",
        "    tf_list = []\n",
        "    for document in corpus:\n",
        "        term_freq_dict = {}\n",
        "        total_words = len(document.split())\n",
        "        for word in document.split():\n",
        "            term_freq_dict[word] = term_freq_dict.get(word, 0) + 1\n",
        "\n",
        "        for word, freq in term_freq_dict.items():\n",
        "            term_freq_dict[word] = round(freq / total_words, 2)\n",
        "\n",
        "        tf_list.append(term_freq_dict)\n",
        "\n",
        "    return tf_list\n",
        "\n",
        "tf_results = calculate_tf(documents)\n",
        "df_tf = pd.DataFrame(tf_results).fillna(0)\n"
      ],
      "metadata": {
        "id": "Nxy8QFsrADKJ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find inverse document frequency\n",
        "def calculate_idf(corpus):\n",
        "    N = len(corpus)\n",
        "    term_doc_count = {}\n",
        "    for document in corpus:\n",
        "        unique_terms = set(document.split())\n",
        "        for term in unique_terms:\n",
        "            term_doc_count[term] = term_doc_count.get(term, 0) + 1\n",
        "\n",
        "    idf_dict = {}\n",
        "    for term, doc_count in term_doc_count.items():\n",
        "        idf_dict[term] = round(math.log(N / (1 + doc_count)), 2)\n",
        "\n",
        "    return idf_dict\n",
        "\n",
        "idf_dict = calculate_idf(documents)\n",
        "df_idf = pd.DataFrame(list(idf_dict.items()), columns=['Term', 'IDF'])\n"
      ],
      "metadata": {
        "id": "lJdwhRmvAGuy"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = round(tfidf_vectorizer.fit_transform(documents), 2)\n",
        "\n",
        "tfidf_tokens = tfidf_vectorizer.get_feature_names_out()\n",
        "df_tfidf = pd.DataFrame(data=tfidf_matrix.toarray(), columns=tfidf_tokens)\n"
      ],
      "metadata": {
        "id": "kdAHqmkTAJNP"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate cosine similarity matrix\n",
        "cosine_similarity_matrix = cosine_similarity(tfidf_matrix)\n",
        "df_cosine_similarity = pd.DataFrame(data=cosine_similarity_matrix)\n",
        "\n",
        "# Calculate Manhattan distance\n",
        "manhattan_distance_s1_s2 = round(1 / cityblock(df_tfidf.iloc[0], df_tfidf.iloc[1]), 2)\n",
        "manhattan_distance_s1_s3 = round(1 / cityblock(df_tfidf.iloc[0], df_tfidf.iloc[2]), 2)\n",
        "manhattan_distance_s2_s3 = round(1 / cityblock(df_tfidf.iloc[1], df_tfidf.iloc[2]), 2)\n",
        "\n",
        "# Calculate Euclidean distances\n",
        "euclidean_distance_s1_s2 = round(math.dist(df_tfidf.iloc[0], df_tfidf.iloc[1]), 2)\n",
        "euclidean_distance_s2_s3 = round(math.dist(df_tfidf.iloc[1], df_tfidf.iloc[2]), 2)\n",
        "euclidean_distance_s1_s3 = round(math.dist(df_tfidf.iloc[0], df_tfidf.iloc[2]), 2)\n",
        "\n",
        "# Display results\n",
        "\n",
        "\n",
        "print(\"\\nTerm Frequency Matrix:\")\n",
        "print(df_tf)\n",
        "\n",
        "print(\"\\nInverse Document Frequency:\")\n",
        "print(df_idf)\n",
        "\n",
        "print(\"\\nTF-IDF Matrix:\")\n",
        "print(df_tfidf)\n",
        "\n",
        "print(\"\\nCosine Similarity Matrix:\")\n",
        "print(df_cosine_similarity)\n",
        "\n",
        "print(\"\\nManhattan Distance:\")\n",
        "print(\"S1 and S2:\", manhattan_distance_s1_s2)\n",
        "print(\"S1 and S3:\", manhattan_distance_s1_s3)\n",
        "print(\"S2 and S3:\", manhattan_distance_s2_s3)\n",
        "\n",
        "print(\"\\nEuclidean Distance:\")\n",
        "print(\"S1 and S2:\", euclidean_distance_s1_s2)\n",
        "print(\"S2 and S3:\", euclidean_distance_s2_s3)\n",
        "print(\"S1 and S3:\", euclidean_distance_s1_s3)\n"
      ],
      "metadata": {
        "id": "pGzed5G-1aDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d9cfc6-a8e7-4f86-da11-821965445c7a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Term Frequency Matrix:\n",
            "   data  science    is   one    of   the  most  important  courses    in  \\\n",
            "0  0.08     0.17  0.08  0.08  0.08  0.08  0.08       0.08     0.08  0.08   \n",
            "1  0.11     0.11  0.11  0.11  0.11  0.11  0.00       0.00     0.11  0.00   \n",
            "2  0.33     0.00  0.00  0.00  0.00  0.17  0.00       0.00     0.00  0.00   \n",
            "\n",
            "   computer  this  best  scientists  perform  analysis  \n",
            "0      0.08  0.00  0.00        0.00     0.00      0.00  \n",
            "1      0.00  0.11  0.11        0.00     0.00      0.00  \n",
            "2      0.00  0.00  0.00        0.17     0.17      0.17  \n",
            "\n",
            "Inverse Document Frequency:\n",
            "          Term   IDF\n",
            "0     computer  0.41\n",
            "1           is  0.00\n",
            "2         data -0.29\n",
            "3          the -0.29\n",
            "4    important  0.41\n",
            "5          one  0.00\n",
            "6           of  0.00\n",
            "7      science  0.00\n",
            "8           in  0.41\n",
            "9      courses  0.00\n",
            "10        most  0.41\n",
            "11        best  0.41\n",
            "12        this  0.41\n",
            "13     perform  0.41\n",
            "14  scientists  0.41\n",
            "15    analysis  0.41\n",
            "\n",
            "TF-IDF Matrix:\n",
            "   analysis  best  computer  courses  data  important    in    is  most    of  \\\n",
            "0      0.00  0.00      0.33     0.25  0.19       0.33  0.33  0.25  0.33  0.25   \n",
            "1      0.00  0.42      0.00     0.32  0.25       0.00  0.00  0.32  0.00  0.32   \n",
            "2      0.46  0.00      0.00     0.00  0.54       0.00  0.00  0.00  0.00  0.00   \n",
            "\n",
            "    one  perform  science  scientists   the  this  \n",
            "0  0.25     0.00     0.50        0.00  0.19  0.00  \n",
            "1  0.32     0.00     0.32        0.00  0.25  0.42  \n",
            "2  0.00     0.46     0.00        0.46  0.27  0.00  \n",
            "\n",
            "Cosine Similarity Matrix:\n",
            "          0         1         2\n",
            "0  1.000000  0.575714  0.153357\n",
            "1  0.575714  1.000000  0.203612\n",
            "2  0.153357  0.203612  1.000000\n",
            "\n",
            "Manhattan Distance:\n",
            "S1 and S2: 0.36\n",
            "S1 and S3: 0.22\n",
            "S2 and S3: 0.24\n",
            "\n",
            "Euclidean Distance:\n",
            "S1 and S2: 0.92\n",
            "S2 and S3: 1.26\n",
            "S1 and S3: 1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pFXuP-Rs9osv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}